{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/liwc_raw_scores.csv') \n",
    "X = df.drop(['party','userid'], axis=1)\n",
    "y = df['party']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=1, stratify=y)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "\n",
    "y_train_encoded = label_encoder.transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "y_train_category = to_categorical(y_train_encoded)\n",
    "y_test_category = to_categorical(y_test_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 0s - loss: 0.7895 - acc: 0.5758\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.5888 - acc: 0.7083\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.5052 - acc: 0.7538\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.4659 - acc: 0.7803\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.4276 - acc: 0.8295\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.4228 - acc: 0.7992\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.3882 - acc: 0.8220\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.3671 - acc: 0.8371\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.3507 - acc: 0.8409\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.3458 - acc: 0.8485\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.3272 - acc: 0.8523\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.3410 - acc: 0.8447\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.3296 - acc: 0.8636\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.3107 - acc: 0.8561\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.2936 - acc: 0.8712\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.2914 - acc: 0.8561\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.3002 - acc: 0.8598\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.2923 - acc: 0.8902\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.2831 - acc: 0.8902\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.3062 - acc: 0.8598\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.3386 - acc: 0.8485\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.3249 - acc: 0.8523\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.2741 - acc: 0.8864\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.2683 - acc: 0.8788\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.2482 - acc: 0.8939\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.2181 - acc: 0.9129\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.2198 - acc: 0.9129\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.2191 - acc: 0.9129\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.2071 - acc: 0.9091\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.1911 - acc: 0.9205\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.2212 - acc: 0.9053\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.2402 - acc: 0.8939\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.1793 - acc: 0.9242\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.1833 - acc: 0.9242\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.1639 - acc: 0.9394\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.1657 - acc: 0.9432\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.1490 - acc: 0.9508\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.1349 - acc: 0.9697\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.1455 - acc: 0.9659\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.1374 - acc: 0.9583\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.1203 - acc: 0.9621\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.1213 - acc: 0.9659\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.1295 - acc: 0.9621\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.1081 - acc: 0.9811\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.1075 - acc: 0.9697\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.1198 - acc: 0.9621\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.0921 - acc: 0.9848\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.0842 - acc: 0.9773\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.0849 - acc: 0.9811\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.1000 - acc: 0.9621\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.0772 - acc: 0.9886\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.0776 - acc: 0.9924\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.1033 - acc: 0.9659\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.0757 - acc: 0.9811\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.0688 - acc: 0.9924\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.0716 - acc: 0.9811\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.0687 - acc: 0.9848\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.0609 - acc: 0.9848\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.0501 - acc: 0.9962\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.0469 - acc: 0.9962\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.0656 - acc: 0.9811\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.0670 - acc: 0.9848\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.0469 - acc: 1.0000\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.0442 - acc: 0.9962\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.0352 - acc: 1.0000\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.0320 - acc: 1.0000\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.0296 - acc: 1.0000\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.0272 - acc: 1.0000\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.0271 - acc: 1.0000\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.0250 - acc: 1.0000\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.0251 - acc: 1.0000\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.0391 - acc: 1.0000\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.0333 - acc: 0.9962\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.0279 - acc: 1.0000\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.0211 - acc: 1.0000\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.0248 - acc: 1.0000\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.0227 - acc: 1.0000\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.0179 - acc: 1.0000\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.0201 - acc: 1.0000\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.0216 - acc: 1.0000\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.0214 - acc: 1.0000\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.0211 - acc: 1.0000\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.0187 - acc: 1.0000\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.0154 - acc: 1.0000\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.0136 - acc: 1.0000\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.0176 - acc: 1.0000\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.0168 - acc: 1.0000\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.0161 - acc: 1.0000\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.0180 - acc: 1.0000\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.0132 - acc: 1.0000\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.0131 - acc: 1.0000\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.0131 - acc: 1.0000\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.0102 - acc: 1.0000\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.0100 - acc: 1.0000\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.0089 - acc: 1.0000\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.0077 - acc: 1.0000\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.0073 - acc: 1.0000\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.0075 - acc: 1.0000\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.0070 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100,activation='relu', input_dim=X.shape[1]))\n",
    "model.add(Dense(units=100,activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))\n",
    "          \n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "result = model.fit(X_train, y_train_category,epochs=100, shuffle=True,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Neural Network - Loss: 0.6424089352066598, Accuracy: 0.7752808915095383\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test, y_test_category, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5757575757575758, 0.7083333333333334, 0.7537878787878788, 0.7803030303030303, 0.8295454545454546, 0.7992424242424242, 0.821969696969697, 0.8371212121212122, 0.8409090909090909, 0.8484848484848485, 0.8522727272727273, 0.8446969696969697, 0.8636363636363636, 0.8560606060606061, 0.8712121212121212, 0.8560606060606061, 0.8598484848484849, 0.8901515151515151, 0.8901515151515151, 0.8598484848484849, 0.8484848484848485, 0.8522727272727273, 0.8863636363636364, 0.8787878787878788, 0.8939393939393939, 0.9128787878787878, 0.9128787878787878, 0.9128787878787878, 0.9090909090909091, 0.9204545454545454, 0.9053030303030303, 0.8939393939393939, 0.9242424242424242, 0.9242424242424242, 0.9393939393939394, 0.9431818181818182, 0.9507575757575758, 0.9696969696969697, 0.9659090909090909, 0.9583333333333334, 0.9621212121212122, 0.9659090909090909, 0.9621212121212122, 0.9810606060606061, 0.9696969696969697, 0.9621212121212122, 0.9848484848484849, 0.9772727272727273, 0.9810606060606061, 0.9621212121212122, 0.9886363636363636, 0.9924242424242424, 0.9659090909090909, 0.9810606060606061, 0.9924242424242424, 0.9810606060606061, 0.9848484848484849, 0.9848484848484849, 0.9962121212121212, 0.9962121212121212, 0.9810606060606061, 0.9848484848484849, 1.0, 0.9962121212121212, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9962121212121212, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.7895190300363483, 0.588774359587467, 0.5051914507692511, 0.4658560680620598, 0.4275998364795338, 0.42284695758964075, 0.3882496311809077, 0.3671339623855822, 0.35066910313837457, 0.34584655183734314, 0.32715641684604413, 0.3410200702421593, 0.3295506311185432, 0.3107162903655659, 0.29364793047760473, 0.2913875977198283, 0.30023200448715326, 0.29233884359851026, 0.283146729071935, 0.3061668032949621, 0.3386094452756824, 0.324941589976802, 0.27406062682469684, 0.2682626256437013, 0.24823690183234937, 0.21813308334711826, 0.21983630458513895, 0.2191246703944423, 0.2071371986107393, 0.19114220819690012, 0.22115770162958087, 0.2401645824764714, 0.17932183092290704, 0.18326774284695135, 0.16388338352694656, 0.16565873157797437, 0.1489687038190437, 0.13492429572524448, 0.14554498863942694, 0.13741824866244287, 0.12028884029749667, 0.1213382479142059, 0.12946811815102896, 0.10811986571008508, 0.10750957600998157, 0.11982610490116657, 0.0921157452870499, 0.0842116168051055, 0.0848782200253371, 0.10002520364342314, 0.07723490351980383, 0.07755186482135093, 0.10333402206500371, 0.0756780244974476, 0.0688273829944206, 0.07163872637531975, 0.0686735583074165, 0.06087640379414414, 0.05009845373305408, 0.04691486749233621, 0.06563747504895384, 0.06703247446002382, 0.04686625053485235, 0.044227810350782944, 0.03522356983387109, 0.032037552925899174, 0.029610747189232796, 0.027222999456253918, 0.027111543568246292, 0.02496097699710817, 0.025145169911962566, 0.039069037320035874, 0.033253460162968346, 0.0279049121520736, 0.021142816269826708, 0.024847958519151718, 0.0227249733200579, 0.017883566575068417, 0.020138513296842575, 0.021648363210260868, 0.021421554695927734, 0.02107188229759534, 0.018703955028093223, 0.015363370717474909, 0.013605724850838835, 0.017636436799710446, 0.016849915405283824, 0.016108423457339857, 0.017955509945750237, 0.013164973055774515, 0.013102402374374144, 0.013127848562417608, 0.010248661097703558, 0.00996068107655667, 0.00893046534761335, 0.008113887407958056, 0.00773929918862202, 0.0073436425829475575, 0.0075045881553016825, 0.006960862231525508]\n"
     ]
    }
   ],
   "source": [
    "print(result.history['acc'])\n",
    "print(result.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "exDict = {'model_loss': model_loss, 'model_accuracy' : model_accuracy, \n",
    "          'acc':result.history['acc'], 'loss' :result.history['loss']}\n",
    "\n",
    "with open('data/matrix/file.txt', 'w') as file:\n",
    "     file.write(json.dumps(exDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = json.load(open(\"data/matrix/file.txt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(\"models/raw_full.h5\")\n",
    "#test = np.expand_dims(X_train[0], axis=0)\n",
    "\n",
    "y_prob = model.predict(X_train[:1])\n",
    "model.predict_classes(X_train[:1])\n",
    "print(f\"Predicted class: {model.predict_classes(X_train[5:6])}\")\n",
    "y_classes = y_prob.argmax(axis=-1)\n",
    "y_prob\n",
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(\"models/raw_full.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test[:10])\n",
    "prediction_labels = label_encoder.inverse_transform(predictions)\n",
    "prediction_labels\n",
    "\n",
    "print(f\"Predicted classes: {prediction_labels}\")\n",
    "print(f\"Actual Labels: {list(y_test[:10])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.fit(X_train, y_train_category,epochs=100, shuffle=True,verbose=2)\n",
    "#history = model.fit(X, Y, validation_split=0.33, nb_epoch=150, batch_size=10, verbose=0)\n",
    "print(result.history['acc'])\n",
    "print(result.history['loss'])\n",
    "\n",
    "#print(result.history.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X,y)\n",
    "\n",
    "imp_feature = rf.feature_importances_\n",
    "sorted_feature = np.argsort(imp_feature)\n",
    "pos = np.arange(sorted_feature.shape[0]) + 0.5\n",
    "plt.barh(pos, imp_feature[sorted_feature], align='center', color='darkgreen')\n",
    "plt.title('Feature Importance')\n",
    "plt.xlabel('Relative Feature Importance')\n",
    "plt.yticks(pos, X.columns[sorted_feature])\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history = model.fit(x, y, validation_split=0.25, epochs=50, batch_size=16, verbose=1)\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
