{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import length\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vector\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark import SparkFiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = SparkSession.builder.appName('nlp').getOrCreate()\n",
    "session.sparkContext.addFile('tweet_data_nlp.csv')\n",
    "df = session.read.csv(SparkFiles.get('tweet_data_nlp.csv'), sep=',', header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+---------+--------------------+------+\n",
      "|Unnamed: 0|            key|    party|                text|length|\n",
      "+----------+---------------+---------+--------------------+------+\n",
      "|         0| RepDarrenSoto0|democrats|And Episode 2 cov...|  3092|\n",
      "|         1| RepDarrenSoto1|democrats|TorresBruno famil...|  3002|\n",
      "|         2| RepDarrenSoto2|democrats|SteveLemongello g...|  2657|\n",
      "|         3| RepDarrenSoto3|democrats|On this NetNeutra...|  3058|\n",
      "|         4| RepDarrenSoto4|democrats|Happy VeteransDay...|  3336|\n",
      "|         5| RepDarrenSoto5|democrats|Today we mourn th...|  3257|\n",
      "|         6| RepDarrenSoto6|democrats| HispanicFed This...|  2775|\n",
      "|         7| RepDarrenSoto7|democrats| NHCSL We are ple...|  2902|\n",
      "|         8| RepDarrenSoto8|democrats| rvivian370 RepDa...|  2875|\n",
      "|         9| RepDarrenSoto9|democrats| ConsulMexOrl En ...|  2944|\n",
      "|        10|RepDarrenSoto10|democrats| LisaKFrank1 Than...|  3219|\n",
      "|        11|RepDarrenSoto11|democrats|Our prayers go ou...|  2869|\n",
      "|        12|RepDarrenSoto12|democrats|Cohens plea admit...|  3174|\n",
      "|        13|RepDarrenSoto13|democrats| FLDaily Darren S...|  3244|\n",
      "|        14|RepDarrenSoto14|democrats| RepJoshG Our Bre...|  3063|\n",
      "|        15|RepDarrenSoto15|democrats|Jediabetic1 I hav...|  3059|\n",
      "|        16|RepDarrenSoto16|democrats| garywhite13 RepD...|  3451|\n",
      "|        17|RepDarrenSoto17|democrats| CHeathWFTV After...|  3043|\n",
      "|        18|RepDarrenSoto18|democrats| Juansabinesg Pro...|  2937|\n",
      "|        19|RepDarrenSoto19|democrats| garywhite13 U.S....|  3315|\n",
      "+----------+---------------+---------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('length', length(df['text']))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = StringIndexer(inputCol='party',outputCol='label')\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"token_text\")\n",
    "stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n",
    "hashingTF = HashingTF(inputCol=\"token_text\", outputCol='hash_token')\n",
    "idf = IDF(inputCol='hash_token', outputCol='idf_token')\n",
    "clean_up = VectorAssembler(inputCols=['idf_token', 'length'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(stages=[labels, tokenizer, stopremove, hashingTF, idf, clean_up])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(262145,[1536,559...|\n",
      "|  0.0|(262145,[2555,405...|\n",
      "|  0.0|(262145,[1536,243...|\n",
      "|  0.0|(262145,[1843,390...|\n",
      "|  0.0|(262145,[1846,232...|\n",
      "|  0.0|(262145,[1226,214...|\n",
      "|  0.0|(262145,[632,2718...|\n",
      "|  0.0|(262145,[304,664,...|\n",
      "|  0.0|(262145,[329,2326...|\n",
      "|  0.0|(262145,[632,1536...|\n",
      "|  0.0|(262145,[632,2731...|\n",
      "|  0.0|(262145,[1772,538...|\n",
      "|  0.0|(262145,[211,316,...|\n",
      "|  0.0|(262145,[168,784,...|\n",
      "|  0.0|(262145,[2437,523...|\n",
      "|  0.0|(262145,[890,1016...|\n",
      "|  0.0|(262145,[2326,386...|\n",
      "|  0.0|(262145,[1921,232...|\n",
      "|  0.0|(262145,[1536,302...|\n",
      "|  0.0|(262145,[441,1138...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaner = pipe.fit(df)\n",
    "cleaned = cleaner.transform(df)\n",
    "cleaned.select(['label', 'features']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+---------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|Unnamed: 0|            key|    party|                text|length|label|          token_text|         stop_tokens|          hash_token|           idf_token|            features|       rawPrediction|         probability|prediction|\n",
      "+----------+---------------+---------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|       103|   RepTedLieu14|democrats| CNNSitRoom Stati...|  3447|  0.0|[, cnnsitroom, st...|[, cnnsitroom, st...|(262144,[3082,408...|(262144,[3082,408...|(262145,[3082,408...|[-14339.919796545...|[1.0,6.9413084558...|       0.0|\n",
      "|       106|   RepTedLieu17|democrats|Today we commemor...|  3757|  0.0|[today, we, comme...|[today, commemora...|(262144,[211,854,...|(262144,[211,854,...|(262145,[211,854,...|[-15669.988172558...|[1.0,1.1731017300...|       0.0|\n",
      "|        11|RepDarrenSoto11|democrats|Our prayers go ou...|  2869|  0.0|[our, prayers, go...|[prayers, go, fam...|(262144,[1772,538...|(262144,[1772,538...|(262145,[1772,538...|[-11095.910119888...|           [1.0,0.0]|       0.0|\n",
      "|       114|RepStephMurphy3|democrats|Skilled and carin...|  4403|  0.0|[skilled, and, ca...|[skilled, caring,...|(262144,[3578,410...|(262144,[3578,410...|(262145,[3578,410...|[-18180.249509919...|[1.0,1.1857027301...|       0.0|\n",
      "|       117|RepStephMurphy6|democrats|...After each of ...|  4441|  0.0|[...after, each, ...|[...after, traged...|(262144,[2089,232...|(262144,[2089,232...|(262145,[2089,232...|[-19299.860651609...|           [1.0,0.0]|       0.0|\n",
      "+----------+---------------+---------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training, testing = cleaned.randomSplit([0.7, 0.3])\n",
    "nb = NaiveBayes()\n",
    "predictor = nb.fit(training)\n",
    "test_results = predictor.transform(testing)\n",
    "test_results.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model at predicting reviews was: 0.9906542056074767\n"
     ]
    }
   ],
   "source": [
    "acc_eval = MulticlassClassificationEvaluator()\n",
    "acc = acc_eval.evaluate(test_results)\n",
    "print(f\"Accuracy of model at predicting affilcation was: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_p = pd.read_csv('compact_tweets.csv')\n",
    "df_p.drop(columns=['Unnamed: 0'])\n",
    "#df_p.to_csv('tweet_data_nlp.csv',columns=['key','party','text'], index=False)\n",
    "df_p['text'] = df_p['text'].apply(lambda x: x.replace('\\n',''))\n",
    "df_p['text'] = df_p['text'].apply(lambda x: x.replace('. ','.'))\n",
    "df_p['text'] = df_p['text'].apply(lambda x: x.replace(' .','.'))\n",
    "\n",
    "\n",
    "df_p.to_csv('tweet_data_nlp.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
