{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import length\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vector\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark import SparkFiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = SparkSession.builder.appName('nlp').getOrCreate()\n",
    "session.sparkContext.addFile('tweet_data_nlp.csv')\n",
    "df = session.read.csv(SparkFiles.get('tweet_data_nlp.csv'), sep=',', header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+---------+--------------------+------+\n",
      "|Unnamed: 0|            key|    party|                text|length|\n",
      "+----------+---------------+---------+--------------------+------+\n",
      "|         0| RepDarrenSoto0|democrats|And Episode 2 cov...|  3092|\n",
      "|         1| RepDarrenSoto1|democrats|TorresBruno famil...|  3002|\n",
      "|         2| RepDarrenSoto2|democrats|SteveLemongello g...|  2657|\n",
      "|         3| RepDarrenSoto3|democrats|On this NetNeutra...|  3058|\n",
      "|         4| RepDarrenSoto4|democrats|Happy VeteransDay...|  3336|\n",
      "|         5| RepDarrenSoto5|democrats|Today we mourn th...|  3257|\n",
      "|         6| RepDarrenSoto6|democrats| HispanicFed This...|  2775|\n",
      "|         7| RepDarrenSoto7|democrats| NHCSL We are ple...|  2902|\n",
      "|         8| RepDarrenSoto8|democrats| rvivian370 RepDa...|  2875|\n",
      "|         9| RepDarrenSoto9|democrats| ConsulMexOrl En ...|  2944|\n",
      "|        10|RepDarrenSoto10|democrats| LisaKFrank1 Than...|  3219|\n",
      "|        11|RepDarrenSoto11|democrats|Our prayers go ou...|  2869|\n",
      "|        12|RepDarrenSoto12|democrats|Cohens plea admit...|  3174|\n",
      "|        13|RepDarrenSoto13|democrats| FLDaily Darren S...|  3244|\n",
      "|        14|RepDarrenSoto14|democrats| RepJoshG Our Bre...|  3063|\n",
      "|        15|RepDarrenSoto15|democrats|Jediabetic1 I hav...|  3059|\n",
      "|        16|RepDarrenSoto16|democrats| garywhite13 RepD...|  3451|\n",
      "|        17|RepDarrenSoto17|democrats| CHeathWFTV After...|  3043|\n",
      "|        18|RepDarrenSoto18|democrats| Juansabinesg Pro...|  2937|\n",
      "|        19|RepDarrenSoto19|democrats| garywhite13 U.S....|  3315|\n",
      "+----------+---------------+---------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('length', length(df['text']))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = StringIndexer(inputCol='party',outputCol='label')\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"token_text\")\n",
    "stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n",
    "hashingTF = HashingTF(inputCol=\"token_text\", outputCol='hash_token')\n",
    "idf = IDF(inputCol='hash_token', outputCol='idf_token')\n",
    "clean_up = VectorAssembler(inputCols=['idf_token', 'length'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(stages=[labels, tokenizer, stopremove, hashingTF, idf, clean_up])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = pipe.fit(df)\n",
    "cleaned = cleaner.transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|         stop_tokens|          hash_token|           idf_token|            features|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|[episode, 2, cove...|(262144,[1536,559...|(262144,[1536,559...|(262145,[1536,559...|\n",
      "|[torresbruno, fam...|(262144,[2555,405...|(262144,[2555,405...|(262145,[2555,405...|\n",
      "|[stevelemongello,...|(262144,[1536,243...|(262144,[1536,243...|(262145,[1536,243...|\n",
      "|[netneutrality, d...|(262144,[1843,390...|(262144,[1843,390...|(262145,[1843,390...|\n",
      "|[happy, veteransd...|(262144,[1846,232...|(262144,[1846,232...|(262145,[1846,232...|\n",
      "|[today, mourn, lo...|(262144,[1226,214...|(262144,[1226,214...|(262145,[1226,214...|\n",
      "|[, hispanicfed, w...|(262144,[632,2718...|(262144,[632,2718...|(262145,[632,2718...|\n",
      "|[, nhcsl, pleased...|(262144,[304,664,...|(262144,[304,664,...|(262145,[304,664,...|\n",
      "|[, rvivian370, re...|(262144,[329,2326...|(262144,[329,2326...|(262145,[329,2326...|\n",
      "|[, consulmexorl, ...|(262144,[632,1536...|(262144,[632,1536...|(262145,[632,1536...|\n",
      "|[, lisakfrank1, t...|(262144,[632,2731...|(262144,[632,2731...|(262145,[632,2731...|\n",
      "|[prayers, go, fam...|(262144,[1772,538...|(262144,[1772,538...|(262145,[1772,538...|\n",
      "|[cohens, plea, ad...|(262144,[211,316,...|(262144,[211,316,...|(262145,[211,316,...|\n",
      "|[, fldaily, darre...|(262144,[168,784,...|(262144,[168,784,...|(262145,[168,784,...|\n",
      "|[, repjoshg, brea...|(262144,[2437,523...|(262144,[2437,523...|(262145,[2437,523...|\n",
      "|[jediabetic1, ins...|(262144,[890,1016...|(262144,[890,1016...|(262145,[890,1016...|\n",
      "|[, garywhite13, r...|(262144,[2326,386...|(262144,[2326,386...|(262145,[2326,386...|\n",
      "|[, cheathwftv, ra...|(262144,[1921,232...|(262144,[1921,232...|(262145,[1921,232...|\n",
      "|[, juansabinesg, ...|(262144,[1536,302...|(262144,[1536,302...|(262145,[1536,302...|\n",
      "|[, garywhite13, u...|(262144,[441,1138...|(262144,[441,1138...|(262145,[441,1138...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned.select(['stop_tokens', 'hash_token','idf_token','features']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+---------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|Unnamed: 0|            key|    party|                text|length|label|          token_text|         stop_tokens|          hash_token|           idf_token|            features|       rawPrediction|         probability|prediction|\n",
      "+----------+---------------+---------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|       105|   RepTedLieu16|democrats|Today w RepAnthon...|  3795|  0.0|[today, w, repant...|[today, w, repant...|(262144,[571,2525...|(262144,[571,2525...|(262145,[571,2525...|[-15320.806060385...|[1.0,6.2757417601...|       0.0|\n",
      "|       108|   RepTedLieu19|democrats| CaucusOnClimate ...|  3630|  0.0|[, caucusonclimat...|[, caucusonclimat...|(262144,[2710,538...|(262144,[2710,538...|(262145,[2710,538...|[-14382.689654730...|[1.0,3.5537916756...|       0.0|\n",
      "|       111|RepStephMurphy0|democrats|RepRickLarsen Der...|  4371|  0.0|[repricklarsen, d...|[repricklarsen, d...|(262144,[1618,192...|(262144,[1618,192...|(262145,[1618,192...|[-18288.934279088...|[1.0,7.2224950996...|       0.0|\n",
      "|       116|RepStephMurphy5|democrats|On NationalComing...|  4443|  0.0|[on, nationalcomi...|[nationalcomingou...|(262144,[2089,271...|(262144,[2089,271...|(262145,[2089,271...|[-18101.648527925...|[1.0,2.9926330161...|       0.0|\n",
      "|        12|RepDarrenSoto12|democrats|Cohens plea admit...|  3174|  0.0|[cohens, plea, ad...|[cohens, plea, ad...|(262144,[211,316,...|(262144,[211,316,...|(262145,[211,316,...|[-11686.846738723...|           [1.0,0.0]|       0.0|\n",
      "+----------+---------------+---------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training, testing = cleaned.randomSplit([0.7, 0.3])\n",
    "nb = NaiveBayes()\n",
    "predictor = nb.fit(training)\n",
    "test_results = predictor.transform(testing)\n",
    "test_results.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model at predicting affilcation was: 1.0\n"
     ]
    }
   ],
   "source": [
    "acc_eval = MulticlassClassificationEvaluator()\n",
    "acc = acc_eval.evaluate(test_results)\n",
    "print(f\"Accuracy of model at predicting affilcation was: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_p = pd.read_csv('compact_tweets.csv')\n",
    "df_p.drop(columns=['Unnamed: 0'])\n",
    "#df_p.to_csv('tweet_data_nlp.csv',columns=['key','party','text'], index=False)\n",
    "df_p['text'] = df_p['text'].apply(lambda x: x.replace('\\n',''))\n",
    "df_p['text'] = df_p['text'].apply(lambda x: x.replace('. ','.'))\n",
    "df_p['text'] = df_p['text'].apply(lambda x: x.replace(' .','.'))\n",
    "\n",
    "\n",
    "df_p.to_csv('tweet_data_nlp.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
